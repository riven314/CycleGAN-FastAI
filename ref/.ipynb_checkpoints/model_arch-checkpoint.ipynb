{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUESTIONS\n",
    "1. What is padding, output_padding in nn.ConvTranspose2d?\n",
    "2. What is ReflectionPad2d v.s. ReplicationPad2d?\n",
    "3. [fastai] transform is applied on tensor or PIL.Image?\n",
    "\n",
    "#### REFERENCE\n",
    "1. fastai notebook on CycleGAN: https://github.com/fastai/course-v3/blob/master/nbs/dl2/cyclegan.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fastai.vision import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../data/horse2zebra/horse2zebra')\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTuple(ItemBase):\n",
    "    def __init__(self, img1, img2):\n",
    "        # img1, img2 = fastai.vision.image.Imagae\n",
    "        self.img1,self.img2 = img1,img2\n",
    "        # img.data is [0 - 1] tensor, converted to [-0.5 - 0.5]\n",
    "        self.obj,self.data = (img1,img2),[-1+2*img1.data,-1+2*img2.data]\n",
    "    \n",
    "    def apply_tfms(self, tfms, **kwargs):\n",
    "        self.img1 = self.img1.apply_tfms(tfms, **kwargs)\n",
    "        self.img2 = self.img2.apply_tfms(tfms, **kwargs)\n",
    "        return self\n",
    "    \n",
    "    def to_one(self): return Image(0.5+torch.cat(self.data,2)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetTupleList(ItemList):\n",
    "    def reconstruct(self, t:Tensor): \n",
    "        if len(t.size()) == 0: return t\n",
    "        # Image input is tensor (C, H, W) -- [0-1]\n",
    "        return ImageTuple(Image(t[0]/2+0.5),Image(t[1]/2+0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTupleList(ImageList):\n",
    "    _label_cls=TargetTupleList\n",
    "    def __init__(self, items, itemsB=None, **kwargs):\n",
    "        self.itemsB = itemsB\n",
    "        super().__init__(items, **kwargs)\n",
    "    \n",
    "    def new(self, items, **kwargs):\n",
    "        return super().new(items, itemsB=self.itemsB, **kwargs)\n",
    "    \n",
    "    def get(self, i):\n",
    "        img1 = super().get(i)\n",
    "        fn = self.itemsB[random.randint(0, len(self.itemsB)-1)]\n",
    "        return ImageTuple(img1, open_image(fn))\n",
    "    \n",
    "    def reconstruct(self, t:Tensor): \n",
    "        return ImageTuple(Image(t[0]/2+0.5),Image(t[1]/2+0.5))\n",
    "    \n",
    "    @classmethod\n",
    "    def from_folders(cls, path, folderA, folderB, **kwargs):\n",
    "        itemsB = ImageList.from_folder(path/folderB).items\n",
    "        res = super().from_folder(path/folderA, itemsB=itemsB, **kwargs)\n",
    "        res.path = path\n",
    "        return res\n",
    "    \n",
    "    def show_xys(self, xs, ys, figsize:Tuple[int,int]=(12,6), **kwargs):\n",
    "        \"Show the `xs` and `ys` on a figure of `figsize`. `kwargs` are passed to the show method.\"\n",
    "        rows = int(math.sqrt(len(xs)))\n",
    "        fig, axs = plt.subplots(rows,rows,figsize=figsize)\n",
    "        for i, ax in enumerate(axs.flatten() if rows > 1 else [axs]):\n",
    "            xs[i].to_one().show(ax=ax, **kwargs)\n",
    "        plt.tight_layout()\n",
    "\n",
    "    def show_xyzs(self, xs, ys, zs, figsize:Tuple[int,int]=None, **kwargs):\n",
    "        \"\"\"Show `xs` (inputs), `ys` (targets) and `zs` (predictions) on a figure of `figsize`.\n",
    "        `kwargs` are passed to the show method.\"\"\"\n",
    "        figsize = ifnone(figsize, (12,3*len(xs)))\n",
    "        fig,axs = plt.subplots(len(xs), 2, figsize=figsize)\n",
    "        fig.suptitle('Ground truth / Predictions', weight='bold', size=14)\n",
    "        for i,(x,z) in enumerate(zip(xs,zs)):\n",
    "            x.to_one().show(ax=axs[i,0], **kwargs)\n",
    "            z.to_one().show(ax=axs[i,1], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (ImageTupleList.from_folders(path, 'trainA', 'trainB')\n",
    "                      .split_none()\n",
    "                      .label_empty()\n",
    "                      .transform(get_transforms(), size=128)\n",
    "                      .databunch(bs=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a. Model Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_t_norm_relu(ch_in, ch_out, norm_layer, ks = 3, stride = 2, bias = True):\n",
    "    conv_t = nn.ConvTranspose2d(ch_in, ch_out, kernel_size = ks, stride = stride, \n",
    "                                padding = 1, output_padding = 1, bias = bias)\n",
    "    return [conv_t, norm_layer(ch_out), nn.ReLU(True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_conv_norm_relu(ch_in, ch_out, pad_mode, norm_layer, ks = 3, bias = True,\n",
    "                        pad = 1, stride = 1, activ = True, init = nn.init.kaiming_normal_):\n",
    "    layers = []\n",
    "    if pad_mode == 'reflection':\n",
    "        layers.append(nn.ReflectionPad2d(pad))\n",
    "    elif pad_mode == 'border':\n",
    "        layers.append(nn.ReplicationPad2d(pad))\n",
    "    p = pad if pad_mode == 'zeros' else 0\n",
    "    # same padding\n",
    "    conv = nn.Conv2d(ch_in, ch_out, kernel_size = 3, padding = p, stride = stride, bias = bias)\n",
    "    if init:\n",
    "        init(conv.weight)\n",
    "        if hasattr(conv, 'bias') and hasattr(conv.bias, 'data'): conv.bias.data.fill_(0.)\n",
    "    layers += [conv, norm_layer(ch_out)]\n",
    "    if activ: layers.append(nn.ReLU(True))\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, pad_mode, norm_layer, dropout = 0., bias = True):\n",
    "        super().__init__()\n",
    "        assert pad_mode in ['zeros', 'reflection', 'border'], f'padding {pad_mode} not implemented'\n",
    "        norm_layer = ifnone(norm_layer, nn.InstanceNorm2d)\n",
    "        layers = pad_conv_norm_relu(dim, dim, pad_mode, norm_layer, bias = bias)\n",
    "        if dropout != 0: \n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        layers += pad_conv_norm_relu(dim, dim, pad_mode, norm_layer, bias = bias, activ = False)\n",
    "        self.conv_block = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_generator(ch_in, ch_out, n_ftrs = 64, norm_layer = None, \n",
    "                     dropout = 0., n_blocks = 6, pad_mode = 'reflection'):\n",
    "    norm_layer = ifnone(norm_layer, nn.InstanceNorm2d)\n",
    "    bias = (norm_layer == nn.InstanceNorm2d)\n",
    "    layers = pad_conv_norm_relu(ch_in, n_ftrs, 'reflection', norm_layer, pad = 3, ks = 7, bias = bias)\n",
    "    for i in range(2):\n",
    "        layers += pad_conv_norm_relu(n_ftrs, n_ftrs * 2, 'zeros', norm_layer, stride = 2, bias = bias)\n",
    "        n_ftrs *= 2\n",
    "    layers += [ResnetBlock(n_ftrs, pad_mode, norm_layer, dropout, bias) for _ in range(n_blocks)]\n",
    "    for i in range(2):\n",
    "        layers += conv_t_norm_relu(n_ftrs, n_ftrs // 2, norm_layer, bias = bias)\n",
    "        n_ftrs //= 2\n",
    "    layers += [nn.ReflectionPad2d(3), nn.Conv2d(n_ftrs, ch_out, kernel_size = 7, padding = 0), nn.Tanh()]\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_generator(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_norm_lr(ch_in, ch_out, norm_layer = None, ks = 3, \n",
    "                  bias = True, pad = 1, stride = 1, activ = True,\n",
    "                  slope = 0.2, init = nn.init.kaiming_normal_):\n",
    "    conv = nn.Conv2d(ch_in, ch_out, kernel_size = ks, \n",
    "                     padding = pad, stride = stride, bias = bias)\n",
    "    if init:\n",
    "        # change in-place\n",
    "        init(conv.weight)\n",
    "        if hasattr(conv, 'bias') and hasattr(conv.bias, 'data'): conv.bias.data.fill_(0.)\n",
    "    layers = [conv]\n",
    "    if norm_layer is not None: layers.append(norm_layer(ch_out))\n",
    "    if activ: layers.append(nn.LeakyReLU(slope, inplace = True))\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(ch_in, n_ftrs = 64, n_layers = 3, \n",
    "                   norm_layer = None, sigmoid = False):\n",
    "    norm_layer = ifnone(norm_layer, nn.InstanceNorm2d)\n",
    "    bias = (norm_layer == nn.InstanceNorm2d)\n",
    "    layers = conv_norm_lr(ch_in, n_ftrs, ks = 4, stride = 2, pad = 1)\n",
    "    for i in range(n_layers - 1):\n",
    "        new_ftrs = 2 * n_ftrs if i <= 3 else n_ftrs\n",
    "        layers += conv_norm_lr(n_ftrs, new_ftrs, norm_layer, \n",
    "                               ks = 4, stride = 2, pad = 1, bias = bias)\n",
    "        n_ftrs = new_ftrs\n",
    "    new_ftrs = 2 * n_ftrs if n_layers <= 3 else n_ftrs\n",
    "    layers += conv_norm_lr(n_ftrs, new_ftrs, norm_layer, \n",
    "                           ks = 4, stride = 1, pad = 1, bias = bias)\n",
    "    layers.append(nn.Conv2d(new_ftrs, 1, kernel_size = 4, stride = 1, padding = 1))\n",
    "    if sigmoid: layers.append(nn.Sigmoid)\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b. Integrate All as CycleGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
