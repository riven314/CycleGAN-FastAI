{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.basic_train import LearnerCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks.tensorboard import GANTensorboardWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "PATH = os.path.join(os.getcwd(), '..', '..')\n",
    "sys.path.append(PATH)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fastai.vision import *\n",
    "\n",
    "from src.model_utils.cyclegan import CycleGAN\n",
    "from src.model_utils.databunch import ImageTupleList\n",
    "from src.model_utils.callbacks import CycleGANTrainer\n",
    "from src.model_utils.loss import CycleGanLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "data_dir = Path('../../data/easy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (ImageTupleList.from_folders(data_dir, 'trainA', 'trainB')\n",
    "                          .split_none()\n",
    "                          .label_empty()\n",
    "                          .transform(get_transforms(), size = 56)\n",
    "                          .databunch(bs = 4))\n",
    "cycle_gan = CycleGAN(ch_in = 3, ch_out = 3, \n",
    "                     disc_layers = 3, \n",
    "                     gen_blocks = 5)\n",
    "learn = Learner(data, cycle_gan, \n",
    "                loss_func = CycleGanLoss(cycle_gan), \n",
    "                opt_func = partial(optim.Adam, betas = (0.5, 0.99)),\n",
    "                callback_fns = [CycleGANTrainer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>id_loss</th>\n",
       "      <th>gen_loss</th>\n",
       "      <th>cyc_loss</th>\n",
       "      <th>D_A_loss</th>\n",
       "      <th>D_B_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='3000', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/3000 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /userhome/34/h3509807/fastai/CycleGAN-MultiMNIST/src/model_utils/callbacks.py(48)on_batch_end()\n",
      "-> self.G_A.zero_grad(); self.G_B.zero_grad()\n",
      "(Pdb) l\n",
      " 43  \t        self.gen_smter.add_value(self.loss_func.gen_loss.detach().cpu())\n",
      " 44  \t        self.cyc_smter.add_value(self.loss_func.cyc_loss.detach().cpu())\n",
      " 45  \t\n",
      " 46  \t    def on_batch_end(self, last_input, last_output, **kwargs):\n",
      " 47  \t        set_trace()\n",
      " 48  ->\t        self.G_A.zero_grad(); self.G_B.zero_grad()\n",
      " 49  \t        fake_A, fake_B = last_output[0].detach(), last_output[1].detach()\n",
      " 50  \t        real_A, real_B = last_input\n",
      " 51  \t        self._set_trainable(D_A=True)\n",
      " 52  \t        self.D_A.zero_grad()\n",
      " 53  \t        loss_D_A = 0.5 * (self.crit(self.D_A(real_A), True) + self.crit(self.D_A(fake_A), False))\n",
      "(Pdb) u\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(241)_call_and_update()\n",
      "-> new = ifnone(getattr(cb, f'on_{cb_name}')(**self.state_dict, **kwargs), dict())\n",
      "(Pdb) l\n",
      "236  \t        self.smoothener = SmoothenValue(self.beta)\n",
      "237  \t        self.state_dict:Dict[str,Union[int,float,Tensor]]=_get_init_state()\n",
      "238  \t\n",
      "239  \t    def _call_and_update(self, cb, cb_name, **kwargs)->None:\n",
      "240  \t        \"Call `cb_name` on `cb` and update the inner state.\"\n",
      "241  ->\t        new = ifnone(getattr(cb, f'on_{cb_name}')(**self.state_dict, **kwargs), dict())\n",
      "242  \t        for k,v in new.items():\n",
      "243  \t            if k not in self.state_dict:\n",
      "244  \t                raise Exception(f\"{k} isn't a valid key in the state of the callbacks.\")\n",
      "245  \t            else: self.state_dict[k] = v\n",
      "246  \t\n",
      "(Pdb) cb_name\n",
      "'batch_end'\n",
      "(Pdb) cb\n",
      "CycleGANTrainer\n",
      "learn: Learner(data=ImageDataBunch;\n",
      "\n",
      "Train: LabelList (12000 items)\n",
      "x: ImageTupleList\n",
      "ImageTuple(torch.Size([3, 56, 56]), torch.Size([3, 56, 56])),ImageTuple(torch.Size([3, 56, 56]), torch.Size([3, 56, 56])),ImageTuple(torch.Size([3, 56, 56]), torch.Size([3, 56, 56])),ImageTuple(torch.Size([3, 56, 56]), torch.Size([3, 56, 56])),ImageTuple(torch.Size([3, 56, 56]), torch.Size([3, 56, 56]))\n",
      "y: EmptyLabelList\n",
      ",,,,\n",
      "Path: ../../data/easy;\n",
      "\n",
      "Valid: LabelList (0 items)\n",
      "x: ImageTupleList\n",
      "\n",
      "y: EmptyLabelList\n",
      "\n",
      "Path: ../../data/easy;\n",
      "\n",
      "Test: None, model=CycleGAN(\n",
      "  (D_A): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (D_B): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (G_A): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (11): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (12): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (13): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (14): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (15): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (16): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (19): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (22): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (23): Tanh()\n",
      "  )\n",
      "  (G_B): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (11): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (12): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (13): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (14): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (15): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (16): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (19): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (22): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (23): Tanh()\n",
      "  )\n",
      "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.5, 0.99)), loss_func=CycleGanLoss(\n",
      "  (cgan): CycleGAN(\n",
      "    (D_A): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "      (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (D_B): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "      (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (G_A): Sequential(\n",
      "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (9): ReLU(inplace=True)\n",
      "      (10): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (11): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (12): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (13): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (14): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (15): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (16): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (17): ReLU(inplace=True)\n",
      "      (18): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (19): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (20): ReLU(inplace=True)\n",
      "      (21): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (22): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (23): Tanh()\n",
      "    )\n",
      "    (G_B): Sequential(\n",
      "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (9): ReLU(inplace=True)\n",
      "      (10): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (11): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (12): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (13): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (14): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (15): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (16): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (17): ReLU(inplace=True)\n",
      "      (18): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (19): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (20): ReLU(inplace=True)\n",
      "      (21): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (22): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (23): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (crit): AdaptiveLoss()\n",
      "), metrics=[], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('../../data/easy'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'src.model_utils.callbacks.CycleGANTrainer'>], callbacks=[], layer_groups=[Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "  (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "  (12): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (13): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (14): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (15): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (16): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (17): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (18): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (19): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (20): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "  (21): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (22): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (23): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "  (24): ReflectionPad2d((3, 3, 3, 3))\n",
      "  (25): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "  (26): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (27): ReLU(inplace=True)\n",
      "  (28): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (29): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (30): ReLU(inplace=True)\n",
      "  (31): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (32): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (33): ReLU(inplace=True)\n",
      "  (34): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (35): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (36): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (37): ReLU(inplace=True)\n",
      "  (38): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (39): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (40): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (41): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (42): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (43): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (44): ReLU(inplace=True)\n",
      "  (45): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (46): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (47): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (48): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (49): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (50): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (51): ReLU(inplace=True)\n",
      "  (52): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (53): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (54): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (55): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (56): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (57): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (58): ReLU(inplace=True)\n",
      "  (59): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (60): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (61): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (62): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (63): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (64): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (65): ReLU(inplace=True)\n",
      "  (66): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (67): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (68): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (69): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (70): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (71): ReLU(inplace=True)\n",
      "  (72): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (73): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (74): ReLU(inplace=True)\n",
      "  (75): ReflectionPad2d((3, 3, 3, 3))\n",
      "  (76): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "  (77): Tanh()\n",
      "  (78): ReflectionPad2d((3, 3, 3, 3))\n",
      "  (79): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "  (80): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (81): ReLU(inplace=True)\n",
      "  (82): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (83): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (84): ReLU(inplace=True)\n",
      "  (85): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (86): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (87): ReLU(inplace=True)\n",
      "  (88): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (89): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (90): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (91): ReLU(inplace=True)\n",
      "  (92): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (93): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (94): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (95): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (96): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (97): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (98): ReLU(inplace=True)\n",
      "  (99): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (100): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (101): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (102): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (103): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (104): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (105): ReLU(inplace=True)\n",
      "  (106): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (107): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (108): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (109): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (110): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (111): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (112): ReLU(inplace=True)\n",
      "  (113): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (114): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (115): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (116): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (117): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (118): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (119): ReLU(inplace=True)\n",
      "  (120): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (121): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (122): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (123): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (124): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (125): ReLU(inplace=True)\n",
      "  (126): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (127): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (128): ReLU(inplace=True)\n",
      "  (129): ReflectionPad2d((3, 3, 3, 3))\n",
      "  (130): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "  (131): Tanh()\n",
      ")], add_time=True, silent=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pdb) type(cb)\n",
      "<class 'src.model_utils.callbacks.CycleGANTrainer'>\n",
      "(Pdb) l\n",
      "247  \t    def __call__(self, cb_name, call_mets=True, **kwargs)->None:\n",
      "248  \t        \"Call through to all of the `CallbakHandler` functions.\"\n",
      "249  \t        if call_mets:\n",
      "250  \t            for met in self.metrics: self._call_and_update(met, cb_name, **kwargs)\n",
      "251  \t        for cb in self.callbacks: self._call_and_update(cb, cb_name, **kwargs)\n",
      "252  \t\n",
      "253  \t    def set_dl(self, dl:DataLoader):\n",
      "254  \t        \"Set the current `dl` used.\"\n",
      "255  \t        if hasattr(self, 'cb_dl'): self.callbacks.remove(self.cb_dl)\n",
      "256  \t        if isinstance(dl.dataset, Callback):\n",
      "257  \t            self.callbacks.append(dl.dataset)\n",
      "(Pdb) d\n",
      "> /userhome/34/h3509807/fastai/CycleGAN-MultiMNIST/src/model_utils/callbacks.py(48)on_batch_end()\n",
      "-> self.G_A.zero_grad(); self.G_B.zero_grad()\n",
      "(Pdb) u\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(241)_call_and_update()\n",
      "-> new = ifnone(getattr(cb, f'on_{cb_name}')(**self.state_dict, **kwargs), dict())\n",
      "(Pdb) l\n",
      "236  \t        self.smoothener = SmoothenValue(self.beta)\n",
      "237  \t        self.state_dict:Dict[str,Union[int,float,Tensor]]=_get_init_state()\n",
      "238  \t\n",
      "239  \t    def _call_and_update(self, cb, cb_name, **kwargs)->None:\n",
      "240  \t        \"Call `cb_name` on `cb` and update the inner state.\"\n",
      "241  ->\t        new = ifnone(getattr(cb, f'on_{cb_name}')(**self.state_dict, **kwargs), dict())\n",
      "242  \t        for k,v in new.items():\n",
      "243  \t            if k not in self.state_dict:\n",
      "244  \t                raise Exception(f\"{k} isn't a valid key in the state of the callbacks.\")\n",
      "245  \t            else: self.state_dict[k] = v\n",
      "246  \t\n",
      "(Pdb) self.state_dict\n",
      "{'epoch': 0, 'iteration': 0, 'num_batch': 0, 'skip_validate': False, 'n_epochs': 1, 'pbar': <fastprogress.fastprogress.NBMasterBar object at 0x14f0bcfe9320>, 'metrics': [], 'stop_training': False, 'last_input': [tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]]], device='cuda:0'), tensor([[[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -0.9843],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -0.9294, -0.9529, -0.9529],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -0.9529, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -0.9843],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -0.9294, -0.9529, -0.9529],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -0.9529, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -0.9843],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -0.9294, -0.9529, -0.9529],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -0.9529, -1.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -0.9843, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -0.9922],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -0.9843]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -0.9843, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -0.9922],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -0.9843]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -0.9843, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -0.9922],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -0.9843]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -0.8588, -0.9608, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -0.9686, -0.9451, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -0.9608, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -0.8588, -0.9608, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -0.9686, -0.9451, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -0.9608, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -0.8588, -0.9608, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -0.9686, -0.9451, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -0.9608, -1.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -0.9686, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -0.9686, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -0.9608, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -0.9686, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -0.9686, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -0.9608, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -0.9686, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -0.9686, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -0.9608, -1.0000]]]],\n",
      "       device='cuda:0')], 'last_target': tensor([0, 0, 0, 0], device='cuda:0'), 'train': True, 'stop_epoch': False, 'skip_step': False, 'skip_zero': False, 'skip_bwd': False, 'last_output': [tensor([[[[ 1.4726e-03, -2.8446e-03,  7.8324e-02,  ...,  1.7028e-01,\n",
      "           -3.3888e-02,  1.5718e-01],\n",
      "          [ 6.8685e-02, -6.4588e-02,  3.4011e-02,  ...,  4.8808e-02,\n",
      "            1.5442e-01,  6.8397e-02],\n",
      "          [-1.7480e-02,  5.6437e-02,  1.2118e-01,  ...,  8.4112e-02,\n",
      "            9.4851e-03,  1.0342e-01],\n",
      "          ...,\n",
      "          [ 1.1470e-01,  2.8129e-02,  7.8290e-02,  ..., -5.9740e-01,\n",
      "            8.7371e-01, -4.8538e-02],\n",
      "          [ 1.1643e-01,  1.8045e-01,  7.8843e-02,  ...,  4.1107e-01,\n",
      "            8.9191e-01, -8.2135e-02],\n",
      "          [ 4.7685e-02,  5.0718e-02,  2.5766e-01,  ..., -1.3594e-01,\n",
      "            8.7290e-01,  2.0476e-01]],\n",
      "\n",
      "         [[-5.5776e-02, -1.3045e-01, -8.3887e-02,  ..., -1.6579e-01,\n",
      "           -2.8150e-02, -7.6637e-02],\n",
      "          [-1.2453e-01, -1.4030e-01, -2.1578e-01,  ..., -1.4238e-01,\n",
      "           -2.2181e-01, -6.0927e-02],\n",
      "          [-1.8452e-01, -1.4530e-01, -2.9329e-01,  ..., -2.0901e-01,\n",
      "           -2.1602e-01, -6.6392e-02],\n",
      "          ...,\n",
      "          [-9.6375e-02, -1.1976e-01, -1.6272e-01,  ..., -7.5119e-01,\n",
      "           -7.5732e-01, -5.7313e-01],\n",
      "          [-2.5567e-01, -1.0195e-01, -2.6704e-01,  ...,  6.3403e-02,\n",
      "           -7.6286e-01, -1.9284e-02],\n",
      "          [-1.1732e-01, -2.5929e-02, -1.6616e-01,  ..., -3.5353e-01,\n",
      "            5.4141e-01, -8.1038e-01]],\n",
      "\n",
      "         [[-7.4603e-02, -3.7539e-02, -1.9444e-01,  ..., -4.1698e-02,\n",
      "           -1.2808e-01, -1.4197e-03],\n",
      "          [ 4.2271e-02, -1.8449e-01, -6.6251e-02,  ..., -5.5248e-02,\n",
      "           -9.7940e-02, -9.5815e-02],\n",
      "          [-3.6732e-02, -1.2435e-01, -6.2156e-02,  ..., -9.0797e-02,\n",
      "            9.0806e-02, -6.4623e-02],\n",
      "          ...,\n",
      "          [ 8.9736e-02, -1.4110e-01, -4.6537e-02,  ..., -1.8190e-01,\n",
      "           -6.8752e-01, -8.6157e-01],\n",
      "          [ 1.4684e-02, -1.6345e-01, -8.4581e-02,  ..., -8.5888e-01,\n",
      "           -1.0633e-01, -4.2436e-01],\n",
      "          [-1.2031e-01, -9.6858e-02, -1.1346e-01,  ...,  2.6047e-01,\n",
      "           -2.4092e-01, -4.9397e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0279e-02,  7.2795e-02,  1.6727e-02,  ...,  1.7337e-01,\n",
      "           -1.4720e-02,  1.1950e-01],\n",
      "          [ 3.9466e-02, -3.6431e-02,  4.0580e-02,  ...,  2.1547e-02,\n",
      "            1.0776e-01,  5.6869e-02],\n",
      "          [ 1.1106e-02,  9.9297e-02,  7.2788e-02,  ...,  6.3334e-02,\n",
      "            4.2983e-02,  9.3008e-02],\n",
      "          ...,\n",
      "          [ 7.6569e-02,  3.3575e-02,  5.1985e-02,  ..., -6.4099e-01,\n",
      "            8.8185e-01, -2.7896e-01],\n",
      "          [ 1.1505e-01,  1.6839e-01,  3.9524e-02,  ...,  9.2022e-01,\n",
      "            1.6496e-01,  2.3594e-01],\n",
      "          [ 3.7387e-02,  8.9829e-02,  2.0277e-01,  ...,  6.4319e-01,\n",
      "            7.9691e-01, -2.7196e-01]],\n",
      "\n",
      "         [[-5.1325e-02, -1.4710e-01, -1.5629e-01,  ..., -2.2256e-01,\n",
      "           -9.7744e-02, -7.5613e-02],\n",
      "          [-1.7559e-01, -8.2672e-02, -1.9144e-01,  ..., -8.2677e-02,\n",
      "           -1.6233e-01, -8.3192e-02],\n",
      "          [-1.5358e-01, -9.2195e-02, -2.2314e-01,  ..., -2.2161e-01,\n",
      "           -1.9055e-01, -8.3425e-02],\n",
      "          ...,\n",
      "          [-1.6104e-01, -9.2385e-02, -1.8041e-01,  ..., -9.3281e-01,\n",
      "           -2.8442e-01, -9.0671e-01],\n",
      "          [-2.2216e-01, -7.2780e-02, -2.5802e-01,  ...,  3.7353e-01,\n",
      "           -8.6934e-01, -5.9445e-01],\n",
      "          [-9.0476e-02, -3.7704e-02, -1.7393e-01,  ..., -4.7754e-01,\n",
      "           -2.0579e-01, -7.6068e-01]],\n",
      "\n",
      "         [[-8.2976e-04, -1.2821e-02, -1.5052e-01,  ..., -6.5012e-02,\n",
      "           -8.7635e-02, -1.2111e-02],\n",
      "          [-2.4141e-02, -1.6760e-01, -4.9644e-02,  ..., -2.1255e-02,\n",
      "           -6.6998e-02, -1.0537e-01],\n",
      "          [ 2.5240e-02, -1.0842e-01, -1.8903e-02,  ..., -9.4883e-02,\n",
      "            1.1419e-01, -1.0934e-01],\n",
      "          ...,\n",
      "          [ 3.5332e-02, -1.2231e-01, -2.7263e-02,  ..., -2.8566e-01,\n",
      "           -1.2487e-01, -7.0581e-01],\n",
      "          [-1.8760e-02, -1.5535e-01, -7.4668e-02,  ...,  5.4038e-01,\n",
      "           -9.0426e-01, -5.8221e-01],\n",
      "          [-1.0066e-01, -1.0623e-01, -1.3814e-01,  ..., -4.4306e-02,\n",
      "            2.8317e-02,  1.0636e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.4839e-02,  2.5839e-02,  1.3241e-01,  ...,  1.1631e-01,\n",
      "           -2.5648e-02,  1.8539e-01],\n",
      "          [ 7.3723e-02, -2.3010e-02,  2.6181e-02,  ...,  1.0418e-01,\n",
      "            2.2588e-01,  1.2562e-01],\n",
      "          [ 1.0675e-02,  7.2296e-02,  1.0275e-01,  ...,  1.0437e-01,\n",
      "            7.4177e-02,  1.2420e-01],\n",
      "          ...,\n",
      "          [ 1.2454e-01,  2.6480e-02,  7.4703e-02,  ..., -1.9931e-01,\n",
      "            8.7004e-01, -5.3346e-02],\n",
      "          [ 1.4773e-01,  1.7161e-01,  1.0876e-01,  ...,  6.6590e-01,\n",
      "            7.7168e-01,  9.8663e-02],\n",
      "          [ 2.5706e-02,  9.6366e-02,  2.2713e-01,  ..., -5.9413e-01,\n",
      "            8.5226e-01,  1.6744e-02]],\n",
      "\n",
      "         [[-9.3581e-02, -1.4156e-01, -1.3307e-01,  ..., -2.0274e-01,\n",
      "           -8.6817e-02, -9.6979e-02],\n",
      "          [-4.2754e-02, -9.7729e-02, -2.1880e-01,  ..., -1.0195e-01,\n",
      "           -2.1342e-01, -1.0490e-01],\n",
      "          [-1.3128e-01, -9.3365e-02, -2.4147e-01,  ..., -2.2672e-01,\n",
      "           -2.3808e-01, -6.1066e-02],\n",
      "          ...,\n",
      "          [-1.2818e-01, -1.0695e-01, -1.7544e-01,  ..., -3.9124e-01,\n",
      "           -8.3477e-01, -9.3477e-01],\n",
      "          [-2.3259e-01, -8.6261e-02, -2.4634e-01,  ..., -6.0992e-01,\n",
      "           -5.4873e-01, -2.0830e-01],\n",
      "          [-6.7078e-02, -3.5483e-02, -1.7167e-01,  ..., -5.1745e-01,\n",
      "           -1.0221e-01, -4.9399e-01]],\n",
      "\n",
      "         [[-3.1167e-02,  5.5832e-03, -1.0026e-01,  ..., -6.7434e-02,\n",
      "           -8.0064e-02, -2.1430e-02],\n",
      "          [-1.0119e-02, -1.8416e-01, -2.3700e-02,  ..., -5.0670e-03,\n",
      "           -1.1567e-01, -1.1962e-01],\n",
      "          [-7.1795e-02, -8.3161e-02, -1.7765e-02,  ..., -1.2939e-01,\n",
      "            4.6193e-02, -1.1924e-01],\n",
      "          ...,\n",
      "          [ 8.1581e-02, -1.1702e-01, -1.5188e-02,  ..., -1.0923e-02,\n",
      "           -5.2619e-01, -7.8867e-01],\n",
      "          [ 2.3528e-02, -1.8480e-01, -4.6643e-02,  ..., -4.6116e-01,\n",
      "           -6.3685e-01, -8.3215e-01],\n",
      "          [-1.2006e-01, -1.1065e-01, -1.3677e-01,  ..., -1.4437e-01,\n",
      "           -3.0357e-01, -1.6872e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7805e-02,  5.8560e-02,  3.3845e-02,  ...,  1.4411e-01,\n",
      "           -1.8694e-02,  1.5231e-01],\n",
      "          [ 5.8491e-02, -4.4869e-02,  2.5978e-02,  ...,  2.6073e-02,\n",
      "            1.2747e-01,  4.3838e-02],\n",
      "          [-4.8184e-02,  5.8043e-02,  5.9628e-02,  ...,  7.6972e-02,\n",
      "            5.6674e-02,  9.7778e-02],\n",
      "          ...,\n",
      "          [ 6.2902e-02,  1.8354e-02,  2.1033e-02,  ..., -1.8042e-01,\n",
      "            9.7203e-01,  2.4810e-02],\n",
      "          [ 6.0604e-02,  1.4769e-01,  2.6968e-02,  ...,  7.7044e-01,\n",
      "            8.3296e-01, -6.8467e-01],\n",
      "          [ 6.6698e-02,  6.9962e-02,  2.2408e-01,  ...,  4.8304e-01,\n",
      "            8.6644e-01, -1.4983e-01]],\n",
      "\n",
      "         [[-4.0222e-02, -1.5126e-01, -1.1160e-01,  ..., -1.8281e-01,\n",
      "           -8.4331e-02, -4.5937e-02],\n",
      "          [-1.4151e-01, -9.3568e-02, -1.7216e-01,  ..., -8.7112e-02,\n",
      "           -1.7840e-01, -6.6372e-02],\n",
      "          [-1.7763e-01, -1.1178e-01, -2.2688e-01,  ..., -2.2132e-01,\n",
      "           -2.2642e-01, -9.7546e-02],\n",
      "          ...,\n",
      "          [-1.5158e-01, -1.1649e-01, -1.9262e-01,  ..., -2.8187e-01,\n",
      "           -8.0148e-01, -9.2725e-01],\n",
      "          [-2.1832e-01, -1.0334e-01, -2.0579e-01,  ..., -3.2165e-01,\n",
      "           -1.8080e-01, -8.8034e-01],\n",
      "          [-6.4838e-02, -5.7948e-02, -1.7260e-01,  ..., -7.6708e-01,\n",
      "            6.5004e-02, -7.2779e-01]],\n",
      "\n",
      "         [[-5.3068e-02,  2.2248e-02, -1.3224e-01,  ..., -5.5708e-02,\n",
      "           -1.0400e-01, -1.8235e-02],\n",
      "          [ 1.5836e-02, -1.9848e-01, -6.2135e-02,  ..., -3.7939e-02,\n",
      "           -6.4461e-02, -9.2201e-02],\n",
      "          [-3.4702e-02, -8.3282e-02, -3.2934e-02,  ..., -9.9065e-02,\n",
      "            9.6435e-02, -1.0338e-01],\n",
      "          ...,\n",
      "          [ 6.0531e-02, -1.4207e-01, -4.1239e-02,  ..., -7.3818e-01,\n",
      "           -7.8080e-01, -9.4255e-01],\n",
      "          [-2.8504e-02, -1.3027e-01, -8.6439e-02,  ..., -6.0340e-01,\n",
      "           -9.2425e-01, -9.1211e-01],\n",
      "          [-9.2262e-02, -8.2659e-02, -1.0951e-01,  ..., -8.3821e-01,\n",
      "           -8.0748e-01, -2.6874e-01]]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward>), tensor([[[[-4.2791e-02, -3.1573e-02,  6.1778e-02,  ..., -4.4945e-02,\n",
      "            1.7500e-01,  1.9538e-02],\n",
      "          [ 1.0950e-01, -5.6865e-02,  1.4287e-01,  ...,  1.8404e-02,\n",
      "            2.1875e-01,  7.2747e-02],\n",
      "          [ 1.0207e-01,  8.3202e-04, -5.8846e-02,  ...,  1.4116e-01,\n",
      "            2.5417e-01,  3.9672e-02],\n",
      "          ...,\n",
      "          [ 1.2481e-01,  2.0289e-01,  1.6597e-01,  ...,  1.6550e-02,\n",
      "            3.2779e-01,  1.0845e-01],\n",
      "          [-1.6720e-01,  2.2042e-01,  3.1191e-02,  ...,  5.7714e-02,\n",
      "            2.1446e-01,  5.2010e-02],\n",
      "          [ 2.2871e-01,  1.6661e-01,  2.9330e-01,  ...,  2.3650e-01,\n",
      "            1.7953e-01,  2.0072e-01]],\n",
      "\n",
      "         [[ 7.8614e-02,  6.9732e-02,  2.3454e-01,  ...,  2.3821e-02,\n",
      "            1.1382e-01, -9.7818e-03],\n",
      "          [-5.1814e-02, -1.3755e-01,  5.8318e-02,  ..., -1.1490e-01,\n",
      "           -8.1853e-02, -8.6674e-02],\n",
      "          [ 1.2873e-03, -1.3679e-01,  3.2320e-01,  ..., -1.3884e-01,\n",
      "            1.0955e-01,  2.8703e-02],\n",
      "          ...,\n",
      "          [ 3.4131e-01, -1.0690e-01, -2.8702e-02,  ..., -7.2506e-02,\n",
      "           -4.7044e-02,  7.6062e-03],\n",
      "          [ 3.8323e-01,  1.8210e-02,  3.3501e-01,  ..., -1.4663e-01,\n",
      "            1.8152e-01, -4.9652e-02],\n",
      "          [ 1.7855e-01, -8.1301e-02,  2.0056e-01,  ..., -1.3936e-02,\n",
      "           -1.7818e-02, -1.5226e-01]],\n",
      "\n",
      "         [[ 2.0522e-01,  1.5600e-02,  5.0388e-02,  ...,  8.0975e-02,\n",
      "            1.2393e-01, -8.1951e-02],\n",
      "          [ 1.4197e-01, -1.5647e-01,  1.8224e-01,  ..., -8.3664e-02,\n",
      "            1.3312e-01, -3.9904e-02],\n",
      "          [ 1.2554e-01,  2.4628e-02,  1.3957e-01,  ...,  1.3197e-01,\n",
      "           -1.3748e-02,  9.1346e-02],\n",
      "          ...,\n",
      "          [ 3.0723e-01, -2.8483e-01,  3.6596e-01,  ..., -1.1734e-01,\n",
      "            2.1917e-01,  1.0466e-02],\n",
      "          [ 6.5835e-02,  1.5359e-01,  3.4582e-01,  ...,  3.9558e-03,\n",
      "            7.7989e-03,  5.0560e-02],\n",
      "          [ 3.4171e-01,  2.9162e-02,  1.5101e-01,  ..., -3.4989e-02,\n",
      "            1.1717e-01, -1.4612e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.3069e-02, -2.5973e-02,  6.7760e-02,  ..., -5.0578e-02,\n",
      "            1.6655e-01,  1.3112e-02],\n",
      "          [ 5.3675e-02, -1.0243e-02,  1.4560e-01,  ...,  2.6926e-02,\n",
      "            1.7673e-01,  9.3421e-02],\n",
      "          [ 1.2048e-01,  3.7047e-04, -2.0110e-02,  ...,  1.2160e-01,\n",
      "            2.1163e-01,  6.4468e-02],\n",
      "          ...,\n",
      "          [ 1.7616e-01,  1.6498e-01,  1.6856e-01,  ...,  3.7588e-03,\n",
      "            3.2433e-01,  9.1437e-02],\n",
      "          [-2.3615e-02, -5.0003e-02,  2.6251e-01,  ...,  5.4979e-02,\n",
      "            1.9211e-01,  5.3905e-02],\n",
      "          [ 3.1151e-01,  1.2447e-01,  3.8177e-02,  ...,  2.2710e-01,\n",
      "            2.0028e-01,  1.9863e-01]],\n",
      "\n",
      "         [[ 9.3016e-02,  8.4511e-02,  2.0449e-01,  ...,  4.7529e-02,\n",
      "            9.4680e-02,  2.4036e-03],\n",
      "          [-1.2023e-02, -1.4974e-01,  7.0839e-02,  ..., -1.1896e-01,\n",
      "           -5.5147e-02, -8.3335e-02],\n",
      "          [ 5.1186e-02, -1.1033e-01,  2.9180e-01,  ..., -1.0409e-01,\n",
      "            1.0033e-01,  3.3707e-02],\n",
      "          ...,\n",
      "          [-5.3815e-02,  4.5958e-02, -1.4634e-01,  ..., -8.5560e-02,\n",
      "           -4.5996e-02, -1.0796e-02],\n",
      "          [ 2.8980e-01,  2.5211e-01,  1.8839e-01,  ..., -1.2181e-01,\n",
      "            1.4885e-01, -4.6129e-02],\n",
      "          [-6.0183e-02, -1.1904e-01,  3.5786e-01,  ..., -2.5619e-02,\n",
      "           -2.0869e-02, -1.3810e-01]],\n",
      "\n",
      "         [[ 2.1868e-01,  2.1567e-02,  9.2485e-02,  ...,  8.9328e-02,\n",
      "            1.2365e-01, -8.7342e-02],\n",
      "          [ 1.2016e-01, -1.6838e-01,  1.8447e-01,  ..., -7.4707e-02,\n",
      "            1.2284e-01, -1.1336e-02],\n",
      "          [ 1.4413e-01, -8.3768e-03,  9.7206e-02,  ...,  1.1866e-01,\n",
      "           -8.5039e-03,  7.4411e-02],\n",
      "          ...,\n",
      "          [ 3.2109e-01, -1.8399e-01,  1.5114e-02,  ..., -8.7920e-02,\n",
      "            2.2517e-01,  1.2666e-02],\n",
      "          [ 6.8535e-02, -1.5692e-01, -1.0237e-01,  ...,  1.9389e-02,\n",
      "            2.8767e-02,  4.3852e-02],\n",
      "          [ 1.3858e-01,  1.0472e-03,  7.6007e-02,  ..., -1.2375e-02,\n",
      "            1.1601e-01, -1.4224e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.8321e-02, -3.1378e-02,  6.8537e-02,  ..., -2.8349e-02,\n",
      "            1.8642e-01,  7.6554e-03],\n",
      "          [ 9.4869e-02, -3.6554e-02,  1.3225e-01,  ...,  5.6844e-02,\n",
      "            1.7701e-01,  7.7536e-02],\n",
      "          [ 6.5017e-02, -6.8274e-03, -4.3655e-02,  ...,  1.3683e-01,\n",
      "            2.2984e-01,  5.8338e-02],\n",
      "          ...,\n",
      "          [ 2.6965e-02,  5.1780e-02,  1.8817e-01,  ...,  1.6054e-02,\n",
      "            3.3371e-01,  1.2101e-01],\n",
      "          [ 4.8511e-02, -5.3452e-02, -1.1544e-02,  ...,  4.0740e-02,\n",
      "            2.0165e-01,  4.4706e-02],\n",
      "          [ 2.7709e-01, -6.8107e-02,  1.5058e-01,  ...,  2.2017e-01,\n",
      "            1.9784e-01,  2.1454e-01]],\n",
      "\n",
      "         [[ 1.3208e-01,  5.7514e-02,  1.9464e-01,  ...,  1.7941e-02,\n",
      "            1.0199e-01, -9.7944e-04],\n",
      "          [ 3.4212e-03, -9.0593e-02,  8.6412e-02,  ..., -1.1669e-01,\n",
      "           -5.2871e-02, -6.4028e-02],\n",
      "          [-1.2047e-02, -9.8935e-02,  2.8804e-01,  ..., -9.9142e-02,\n",
      "            9.5675e-02,  4.2088e-02],\n",
      "          ...,\n",
      "          [ 1.8416e-02,  2.9425e-01, -1.0183e-01,  ..., -6.0663e-02,\n",
      "           -4.1755e-02,  4.1335e-03],\n",
      "          [ 1.8667e-01,  7.9012e-02,  1.3277e-01,  ..., -1.3961e-01,\n",
      "            1.5298e-01, -3.1295e-02],\n",
      "          [-6.8407e-02,  1.8426e-01,  5.8748e-02,  ..., -1.3667e-02,\n",
      "           -4.1301e-02, -1.2623e-01]],\n",
      "\n",
      "         [[ 1.8641e-01,  5.3834e-02,  6.5846e-02,  ...,  7.8991e-02,\n",
      "            1.1601e-01, -5.2910e-02],\n",
      "          [ 1.1831e-01, -1.5653e-01,  1.8825e-01,  ..., -7.2112e-02,\n",
      "            1.1559e-01,  4.5260e-03],\n",
      "          [ 1.2474e-01, -1.7565e-02,  1.1002e-01,  ...,  7.8125e-02,\n",
      "           -1.1338e-02,  8.0025e-02],\n",
      "          ...,\n",
      "          [ 1.2495e-01, -2.3525e-01,  2.2959e-01,  ..., -7.4068e-02,\n",
      "            2.1539e-01,  9.5219e-03],\n",
      "          [ 2.2582e-01, -3.1653e-02,  1.8763e-01,  ...,  4.7397e-03,\n",
      "            1.8081e-02,  3.5362e-02],\n",
      "          [ 2.3846e-01,  1.3698e-01,  1.1332e-01,  ..., -2.3067e-02,\n",
      "            1.3258e-01, -9.0029e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.4196e-02, -5.3547e-02,  8.0978e-02,  ..., -3.7341e-02,\n",
      "            1.9066e-01,  3.2968e-02],\n",
      "          [ 6.9551e-02, -1.7212e-02,  1.5067e-01,  ...,  6.0414e-02,\n",
      "            1.9341e-01,  8.6483e-02],\n",
      "          [ 9.1607e-02,  2.5689e-03, -5.0915e-02,  ...,  1.2033e-01,\n",
      "            2.3249e-01,  8.2040e-02],\n",
      "          ...,\n",
      "          [ 5.5844e-02,  2.8217e-01,  2.9091e-01,  ...,  1.6684e-02,\n",
      "            3.1123e-01,  9.0854e-02],\n",
      "          [ 3.8910e-02, -1.8765e-01,  6.4510e-02,  ...,  4.2244e-02,\n",
      "            2.3263e-01,  5.1643e-02],\n",
      "          [ 2.2348e-01, -4.3122e-02,  3.2436e-01,  ...,  2.5604e-01,\n",
      "            1.9908e-01,  1.9110e-01]],\n",
      "\n",
      "         [[ 1.0468e-01,  9.1870e-02,  2.1020e-01,  ...,  2.3771e-02,\n",
      "            9.8478e-02,  6.6659e-03],\n",
      "          [ 1.0910e-02, -9.0539e-02,  8.7102e-02,  ..., -1.2323e-01,\n",
      "           -6.5838e-02, -6.4699e-02],\n",
      "          [ 4.3563e-02, -1.1380e-01,  2.9590e-01,  ..., -1.2013e-01,\n",
      "            1.2288e-01,  4.4224e-02],\n",
      "          ...,\n",
      "          [-1.2571e-02, -3.8323e-02,  6.6148e-02,  ..., -7.8878e-02,\n",
      "           -3.7711e-02, -1.1079e-02],\n",
      "          [ 5.9971e-01, -6.4489e-02,  1.2454e-01,  ..., -1.4996e-01,\n",
      "            1.7654e-01, -1.9635e-02],\n",
      "          [ 2.2169e-01,  4.0524e-02,  1.7986e-01,  ..., -3.0304e-02,\n",
      "           -2.0590e-02, -1.1938e-01]],\n",
      "\n",
      "         [[ 2.1237e-01,  4.0574e-02,  7.1177e-02,  ...,  9.7300e-02,\n",
      "            1.2886e-01, -6.5404e-02],\n",
      "          [ 9.7570e-02, -1.6010e-01,  2.0445e-01,  ..., -8.6301e-02,\n",
      "            1.3467e-01, -1.0177e-02],\n",
      "          [ 1.5429e-01, -1.2998e-02,  1.3117e-01,  ...,  1.0569e-01,\n",
      "           -2.0588e-02,  9.9358e-02],\n",
      "          ...,\n",
      "          [-4.5912e-02, -3.5258e-01,  2.7859e-01,  ..., -8.4043e-02,\n",
      "            2.4923e-01,  2.7656e-02],\n",
      "          [ 3.2810e-02, -8.7663e-05,  1.8129e-01,  ...,  3.0189e-02,\n",
      "            9.3441e-03,  7.8082e-02],\n",
      "          [ 1.3936e-01, -7.3038e-02,  3.4599e-01,  ..., -3.0168e-02,\n",
      "            1.1249e-01, -1.4003e-02]]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward>), tensor([[[[-7.5788e-02,  9.5065e-02, -7.2312e-02,  ...,  1.7247e-01,\n",
      "           -1.8877e-02,  2.0205e-01],\n",
      "          [ 2.5155e-02,  9.2238e-03, -2.4321e-03,  ...,  7.2312e-02,\n",
      "            1.3030e-01,  3.9889e-03],\n",
      "          [ 3.1604e-03,  6.7020e-02,  1.2496e-01,  ...,  1.4062e-01,\n",
      "            8.5972e-02,  1.1616e-01],\n",
      "          ...,\n",
      "          [ 2.1661e-01,  2.6626e-01,  3.0860e-01,  ...,  9.3877e-02,\n",
      "            1.1690e-01,  6.5785e-02],\n",
      "          [ 2.6789e-01,  2.9729e-01,  1.0257e-01,  ...,  1.1259e-01,\n",
      "            1.8630e-02,  1.2499e-01],\n",
      "          [ 1.8827e-01,  1.1988e-01,  2.3587e-01,  ...,  1.3837e-01,\n",
      "            7.6778e-02,  3.5846e-03]],\n",
      "\n",
      "         [[-6.0699e-02, -6.3199e-02, -1.2954e-01,  ..., -1.8326e-01,\n",
      "           -5.7617e-02, -8.1719e-02],\n",
      "          [-1.3978e-01, -1.2256e-01, -2.2496e-01,  ..., -1.2486e-01,\n",
      "           -1.8503e-01, -4.9237e-02],\n",
      "          [-2.2521e-01, -1.3275e-01, -3.0506e-01,  ..., -2.8127e-01,\n",
      "           -2.5036e-01, -1.8434e-02],\n",
      "          ...,\n",
      "          [-1.3288e-02, -9.0664e-02, -3.6294e-01,  ..., -1.2875e-01,\n",
      "           -1.0879e-01, -8.5080e-02],\n",
      "          [-3.9029e-01, -2.5398e-02, -3.8172e-01,  ..., -1.5230e-01,\n",
      "           -2.8994e-01, -4.4762e-02],\n",
      "          [-1.6227e-01,  1.3193e-02, -8.0735e-02,  ..., -1.3987e-01,\n",
      "           -1.0575e-01, -8.1211e-02]],\n",
      "\n",
      "         [[-1.1510e-01, -6.4312e-02, -1.5106e-01,  ..., -4.5469e-02,\n",
      "           -1.7612e-01,  3.2934e-02],\n",
      "          [-5.5394e-04, -1.8549e-01, -8.2807e-03,  ..., -2.1810e-02,\n",
      "           -8.2225e-02, -1.0830e-01],\n",
      "          [-1.6241e-01, -1.6108e-01, -8.2112e-02,  ..., -1.2819e-01,\n",
      "            1.9715e-02, -1.4097e-01],\n",
      "          ...,\n",
      "          [-3.8113e-01, -1.4654e-01, -1.6861e-01,  ..., -5.1279e-02,\n",
      "           -1.8692e-02, -9.9902e-02],\n",
      "          [-2.3323e-01, -3.4954e-01, -6.6950e-02,  ...,  5.4264e-02,\n",
      "           -2.8072e-03,  4.3647e-02],\n",
      "          [ 1.7506e-02, -2.5847e-01, -1.9046e-01,  ..., -1.3415e-01,\n",
      "           -1.7784e-01, -7.5393e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.7181e-02,  8.2649e-02, -7.5142e-02,  ...,  1.7958e-01,\n",
      "           -3.7584e-02,  2.1902e-01],\n",
      "          [ 7.3150e-02, -2.0534e-03,  7.9103e-03,  ...,  9.2376e-02,\n",
      "            1.3279e-01, -2.7575e-02],\n",
      "          [-2.3406e-02,  2.3257e-02,  1.5499e-01,  ...,  1.0053e-01,\n",
      "            5.9934e-02,  8.0158e-02],\n",
      "          ...,\n",
      "          [ 2.9346e-01,  3.8748e-02,  2.0288e-01,  ...,  9.0564e-02,\n",
      "            9.9903e-02,  6.3207e-02],\n",
      "          [ 1.1120e-01,  2.5998e-01,  2.0348e-01,  ...,  1.3601e-01,\n",
      "            6.5855e-03,  1.3266e-01],\n",
      "          [ 8.7084e-02,  2.1618e-01,  1.6516e-01,  ...,  1.4039e-01,\n",
      "            9.4258e-02,  2.5411e-02]],\n",
      "\n",
      "         [[-6.1646e-03, -4.9810e-02, -1.2899e-01,  ..., -2.1413e-01,\n",
      "           -1.7724e-02, -6.1244e-02],\n",
      "          [-1.8357e-01, -1.0025e-01, -2.3788e-01,  ..., -8.9655e-02,\n",
      "           -2.2038e-01, -1.2687e-02],\n",
      "          [-2.0197e-01, -1.1481e-01, -3.0424e-01,  ..., -2.6954e-01,\n",
      "           -2.4661e-01, -1.0536e-03],\n",
      "          ...,\n",
      "          [-1.9951e-01,  2.8239e-02, -4.0623e-01,  ..., -1.2298e-01,\n",
      "           -1.6671e-01, -1.0497e-01],\n",
      "          [-2.8047e-01,  2.1938e-01, -5.4570e-01,  ..., -1.5143e-01,\n",
      "           -2.3630e-01, -3.2693e-02],\n",
      "          [-2.4794e-01, -1.1668e-01, -2.8099e-01,  ..., -1.3981e-01,\n",
      "           -1.3096e-01, -6.0992e-02]],\n",
      "\n",
      "         [[-1.1133e-01, -5.0779e-02, -9.7727e-02,  ..., -5.1597e-02,\n",
      "           -1.7133e-01,  1.7012e-02],\n",
      "          [ 7.3020e-02, -1.4017e-01, -7.3233e-03,  ..., -1.6117e-02,\n",
      "           -7.6645e-02, -1.2562e-01],\n",
      "          [-9.7175e-02, -1.3520e-01, -6.3957e-02,  ..., -1.2246e-01,\n",
      "            2.4451e-02, -1.4649e-01],\n",
      "          ...,\n",
      "          [ 6.1627e-02, -2.2902e-01,  7.8616e-02,  ..., -4.9177e-02,\n",
      "            9.8139e-03, -9.5067e-02],\n",
      "          [-2.2709e-01, -1.0992e-01,  8.5835e-02,  ...,  1.7676e-02,\n",
      "           -3.5942e-02,  1.8091e-02],\n",
      "          [-1.9533e-02, -1.1288e-01, -1.8956e-01,  ..., -1.2154e-01,\n",
      "           -1.8316e-01, -6.0394e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.7287e-02,  9.6065e-02, -6.9794e-02,  ...,  1.9150e-01,\n",
      "           -2.6296e-02,  2.2383e-01],\n",
      "          [ 4.4807e-02,  3.3043e-02,  2.1218e-03,  ...,  1.1082e-01,\n",
      "            1.2325e-01,  1.8644e-04],\n",
      "          [-3.8861e-02,  3.7565e-02,  1.7244e-01,  ...,  1.0219e-01,\n",
      "            6.4065e-02,  7.1537e-02],\n",
      "          ...,\n",
      "          [ 3.4431e-02,  1.9429e-02,  7.0528e-02,  ...,  1.1965e-01,\n",
      "            9.6896e-02,  7.4470e-02],\n",
      "          [-6.7906e-02,  7.6846e-02,  8.9846e-02,  ...,  1.2994e-01,\n",
      "            3.4288e-02,  1.0352e-01],\n",
      "          [ 2.6827e-02,  1.3094e-01,  2.0818e-01,  ...,  1.4859e-01,\n",
      "            5.9681e-02, -1.0805e-02]],\n",
      "\n",
      "         [[ 3.4300e-03, -4.9517e-02, -1.1909e-01,  ..., -2.2397e-01,\n",
      "           -2.2192e-02, -7.9693e-02],\n",
      "          [-1.9260e-01, -1.3589e-01, -2.4018e-01,  ..., -8.1687e-02,\n",
      "           -2.3292e-01,  4.7859e-03],\n",
      "          [-2.1443e-01, -9.2656e-02, -3.3285e-01,  ..., -2.9373e-01,\n",
      "           -2.5094e-01, -1.1859e-02],\n",
      "          ...,\n",
      "          [-1.5585e-01, -1.3544e-01, -5.8156e-02,  ..., -1.2572e-01,\n",
      "           -1.8356e-01, -8.1695e-02],\n",
      "          [-3.9127e-01,  1.1973e-02, -4.0958e-01,  ..., -1.5511e-01,\n",
      "           -2.4933e-01, -3.4831e-02],\n",
      "          [-2.3977e-01,  1.1889e-03, -2.9561e-01,  ..., -1.3659e-01,\n",
      "           -1.3358e-01, -7.5023e-02]],\n",
      "\n",
      "         [[-8.9991e-02, -4.7638e-02, -1.1756e-01,  ..., -4.0172e-02,\n",
      "           -1.8080e-01,  5.9432e-02],\n",
      "          [ 7.8593e-02, -1.8351e-01, -2.6003e-02,  ..., -6.7524e-03,\n",
      "           -6.1944e-02, -1.3972e-01],\n",
      "          [-9.9984e-02, -1.1968e-01, -8.2313e-02,  ..., -1.3666e-01,\n",
      "            4.6039e-02, -1.4759e-01],\n",
      "          ...,\n",
      "          [-1.1820e-01, -6.9919e-02,  1.0127e-03,  ..., -6.0269e-02,\n",
      "           -1.3078e-02, -9.4504e-02],\n",
      "          [ 5.2885e-02, -6.5776e-02,  2.4139e-01,  ...,  3.0199e-02,\n",
      "           -2.8449e-02,  6.7309e-02],\n",
      "          [ 6.4975e-02, -1.8009e-01, -1.7186e-01,  ..., -1.1875e-01,\n",
      "           -1.6861e-01, -6.9254e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.3730e-02,  5.8167e-02, -3.4937e-02,  ...,  2.0203e-01,\n",
      "           -2.0654e-02,  1.7549e-01],\n",
      "          [ 9.8602e-02, -2.6798e-02,  2.1072e-02,  ...,  8.1891e-02,\n",
      "            1.5803e-01,  1.1293e-02],\n",
      "          [-1.4508e-02,  2.8620e-02,  1.5291e-01,  ...,  1.1030e-01,\n",
      "            6.7216e-02,  7.8979e-02],\n",
      "          ...,\n",
      "          [-1.1372e-01,  4.0406e-02, -7.0374e-02,  ...,  1.0709e-01,\n",
      "            9.3359e-02,  5.8880e-02],\n",
      "          [ 2.8677e-01,  4.2013e-01,  1.8703e-01,  ...,  1.5318e-01,\n",
      "            1.4076e-02,  1.1999e-01],\n",
      "          [ 1.8394e-01,  4.3315e-02,  2.3210e-01,  ...,  1.1078e-01,\n",
      "            9.1214e-02, -5.1994e-03]],\n",
      "\n",
      "         [[-2.4137e-03, -8.1967e-03, -1.5820e-01,  ..., -1.9556e-01,\n",
      "           -3.8025e-02, -4.8657e-02],\n",
      "          [-1.6084e-01, -1.4345e-01, -2.3773e-01,  ..., -1.2031e-01,\n",
      "           -2.1842e-01, -3.2116e-02],\n",
      "          [-1.9540e-01, -1.2354e-01, -2.8808e-01,  ..., -2.6029e-01,\n",
      "           -2.2134e-01, -1.3089e-02],\n",
      "          ...,\n",
      "          [-3.3321e-01, -1.4966e-03, -1.8805e-01,  ..., -1.2523e-01,\n",
      "           -1.2956e-01, -8.2510e-02],\n",
      "          [-3.4556e-01, -1.1720e-01, -2.1506e-01,  ..., -1.2980e-01,\n",
      "           -2.5576e-01, -5.8503e-02],\n",
      "          [-1.8443e-01,  1.7069e-01, -1.9819e-01,  ..., -1.3335e-01,\n",
      "           -1.1344e-01, -4.8523e-02]],\n",
      "\n",
      "         [[-5.7134e-02, -3.6295e-02, -9.3819e-02,  ..., -8.2762e-02,\n",
      "           -1.4151e-01,  1.6062e-02],\n",
      "          [ 3.7746e-02, -1.7452e-01,  7.8758e-03,  ...,  8.5810e-03,\n",
      "           -7.1906e-02, -1.2429e-01],\n",
      "          [-1.1914e-01, -1.4106e-01, -5.2802e-02,  ..., -1.3702e-01,\n",
      "            2.8833e-02, -1.5834e-01],\n",
      "          ...,\n",
      "          [ 4.2557e-03, -1.0919e-01,  1.0579e-02,  ..., -2.7609e-02,\n",
      "            1.5609e-02, -7.6705e-02],\n",
      "          [-1.0710e-01, -3.0680e-01,  1.6882e-02,  ..., -1.7253e-02,\n",
      "           -1.5578e-02,  2.6637e-02],\n",
      "          [-2.0351e-01, -2.2800e-01, -9.5605e-02,  ..., -1.2170e-01,\n",
      "           -1.8385e-01, -5.9062e-02]]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward>), tensor([[[[-5.2533e-02, -9.4163e-02,  3.0912e-02,  ..., -5.0382e-02,\n",
      "            1.7429e-01, -3.0494e-02],\n",
      "          [ 1.1466e-01, -3.1249e-02,  1.3114e-01,  ...,  1.5161e-01,\n",
      "            2.2212e-01,  4.7399e-02],\n",
      "          [ 1.1425e-01, -6.7638e-02,  5.2384e-02,  ...,  5.9246e-02,\n",
      "            1.7560e-01,  1.4366e-02],\n",
      "          ...,\n",
      "          [ 2.2581e-01,  5.0535e-02,  2.0650e-01,  ...,  6.2528e-01,\n",
      "            2.7605e-01, -5.0040e-01],\n",
      "          [ 2.1305e-01,  2.6756e-02,  1.4878e-01,  ...,  7.2550e-01,\n",
      "            2.8055e-01, -4.7929e-01],\n",
      "          [ 2.2317e-01,  1.1394e-01,  1.9754e-01,  ..., -7.9460e-01,\n",
      "           -9.9767e-02,  6.8865e-01]],\n",
      "\n",
      "         [[ 9.7423e-02,  5.4239e-02,  1.6915e-01,  ..., -6.2400e-05,\n",
      "            2.3588e-03, -4.4340e-02],\n",
      "          [ 1.0726e-02, -9.4928e-02,  1.1622e-01,  ..., -1.0577e-01,\n",
      "            4.9578e-02, -4.9390e-02],\n",
      "          [ 4.3472e-02, -8.8506e-02,  2.6121e-01,  ..., -2.9117e-02,\n",
      "            8.6023e-02, -3.7300e-02],\n",
      "          ...,\n",
      "          [ 1.6065e-02, -1.6501e-02,  1.6168e-02,  ...,  5.9266e-01,\n",
      "            9.4132e-01, -6.6542e-01],\n",
      "          [ 1.3330e-01, -1.4640e-01,  1.5595e-01,  ..., -3.9288e-01,\n",
      "           -1.1251e-01, -6.3349e-01],\n",
      "          [-6.4463e-02, -1.2250e-01,  3.7182e-02,  ...,  6.6534e-01,\n",
      "            6.5947e-01,  4.3763e-01]],\n",
      "\n",
      "         [[ 2.1584e-01,  7.8359e-02,  8.1506e-02,  ...,  8.2143e-02,\n",
      "            7.6181e-02,  2.9216e-02],\n",
      "          [ 1.7113e-01, -7.5549e-02,  1.9232e-01,  ..., -3.7456e-02,\n",
      "            1.2358e-01,  1.5755e-02],\n",
      "          [ 1.0219e-01, -5.2882e-02,  7.5354e-02,  ...,  1.1411e-01,\n",
      "           -2.6744e-02,  1.3125e-01],\n",
      "          ...,\n",
      "          [ 1.5790e-01, -1.3791e-01,  1.8674e-01,  ..., -2.1583e-01,\n",
      "           -7.1406e-02, -4.9235e-01],\n",
      "          [-5.7304e-02, -3.4438e-02, -3.0977e-02,  ..., -1.7540e-01,\n",
      "            1.6485e-01, -3.8128e-01],\n",
      "          [ 1.8492e-01,  5.9751e-02,  6.2598e-02,  ..., -8.2681e-02,\n",
      "            9.2117e-02, -3.6594e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6293e-02, -1.1097e-01,  8.7843e-02,  ..., -8.3897e-03,\n",
      "            2.0441e-01, -2.4565e-02],\n",
      "          [ 1.1592e-01,  3.4282e-02,  1.3361e-01,  ...,  1.0378e-01,\n",
      "            1.6138e-01,  4.8832e-02],\n",
      "          [ 1.8456e-01, -1.4261e-02,  6.1633e-02,  ...,  8.0806e-02,\n",
      "            2.1227e-01,  2.6686e-03],\n",
      "          ...,\n",
      "          [ 1.8305e-01,  4.0525e-02,  1.8524e-01,  ..., -7.1526e-02,\n",
      "            7.9926e-01, -3.4336e-01],\n",
      "          [ 2.4446e-01,  2.7126e-02,  1.8466e-01,  ...,  6.0433e-01,\n",
      "            2.4149e-01,  2.3822e-02],\n",
      "          [ 2.4172e-01,  1.6177e-01,  1.9281e-01,  ...,  1.2951e-01,\n",
      "           -7.0239e-01,  1.1528e-01]],\n",
      "\n",
      "         [[ 3.6859e-02,  8.1517e-02,  1.0081e-01,  ...,  1.6171e-02,\n",
      "            3.6338e-02, -4.0291e-02],\n",
      "          [-6.1896e-03, -9.6786e-02,  8.3589e-02,  ..., -9.0928e-02,\n",
      "           -3.2912e-02, -7.9156e-02],\n",
      "          [ 3.9484e-02, -6.0499e-02,  1.6728e-01,  ..., -4.6082e-02,\n",
      "            5.0513e-02, -2.4022e-02],\n",
      "          ...,\n",
      "          [-7.5385e-03, -1.1751e-02,  1.1287e-02,  ...,  3.8089e-01,\n",
      "            9.3338e-01,  2.7112e-01],\n",
      "          [ 1.2302e-01, -1.4026e-01,  1.1618e-01,  ...,  5.6555e-01,\n",
      "            5.5329e-01, -5.4762e-01],\n",
      "          [-1.1208e-01, -1.3543e-01, -2.6242e-02,  ..., -3.3490e-01,\n",
      "            7.1340e-01, -2.5914e-01]],\n",
      "\n",
      "         [[ 1.9135e-01,  1.5326e-01,  3.3526e-02,  ...,  1.1724e-01,\n",
      "            8.0982e-02,  1.0232e-02],\n",
      "          [ 9.5049e-02, -6.1113e-02,  1.9899e-01,  ..., -6.3707e-02,\n",
      "            1.3457e-01,  5.6933e-02],\n",
      "          [ 1.0553e-01, -1.8781e-02,  8.5504e-02,  ...,  1.4445e-01,\n",
      "           -4.9703e-02,  1.1563e-01],\n",
      "          ...,\n",
      "          [ 1.9790e-01, -9.8490e-02,  1.7614e-01,  ..., -2.3314e-01,\n",
      "            7.6292e-01,  4.3185e-01],\n",
      "          [-2.3513e-03, -5.8342e-02,  3.1987e-03,  ...,  2.5872e-01,\n",
      "            2.1340e-01, -6.3039e-01],\n",
      "          [ 1.7276e-01,  4.0109e-02,  3.9943e-02,  ...,  4.9673e-01,\n",
      "            1.4655e-01, -2.4594e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8950e-03, -7.6892e-02, -8.5163e-03,  ..., -4.0472e-02,\n",
      "            1.7912e-01, -2.1146e-02],\n",
      "          [ 1.2732e-01, -1.5979e-02,  1.3220e-01,  ...,  8.5756e-02,\n",
      "            2.3602e-01,  7.0134e-02],\n",
      "          [ 1.2662e-01, -3.9217e-02,  1.9696e-02,  ...,  8.4327e-02,\n",
      "            1.9122e-01,  1.9529e-02],\n",
      "          ...,\n",
      "          [ 2.3363e-01,  2.3036e-02,  1.5123e-01,  ...,  1.4985e-01,\n",
      "           -5.9057e-02, -4.5341e-01],\n",
      "          [ 2.9420e-01,  6.9247e-02,  1.5747e-01,  ...,  1.1307e-01,\n",
      "            4.1711e-01,  6.5389e-02],\n",
      "          [ 2.5151e-01,  1.3822e-01,  1.8246e-01,  ..., -6.7724e-01,\n",
      "            4.5979e-01, -5.4088e-01]],\n",
      "\n",
      "         [[ 1.8622e-02,  6.4471e-02,  1.3386e-01,  ...,  2.4622e-02,\n",
      "            1.0574e-02,  8.2582e-03],\n",
      "          [ 4.3269e-02, -1.2914e-01,  1.2196e-01,  ..., -1.1883e-01,\n",
      "            1.4385e-02, -1.0779e-01],\n",
      "          [ 1.2287e-01, -1.0175e-01,  2.8520e-01,  ..., -2.3455e-02,\n",
      "            7.3044e-02, -2.2204e-02],\n",
      "          ...,\n",
      "          [-2.3562e-02, -3.7398e-03, -7.4044e-03,  ...,  6.7425e-01,\n",
      "            9.9557e-02,  2.8481e-01],\n",
      "          [ 9.2278e-02, -1.4797e-01,  1.5427e-01,  ..., -6.3618e-01,\n",
      "            5.4511e-01, -2.5912e-01],\n",
      "          [-4.6365e-02, -1.2722e-01,  4.1545e-02,  ...,  5.4512e-01,\n",
      "            4.5981e-01, -1.2970e-01]],\n",
      "\n",
      "         [[ 2.7116e-01,  6.7982e-02,  1.1403e-01,  ...,  6.7940e-02,\n",
      "            1.2719e-01,  7.4144e-03],\n",
      "          [ 2.0095e-01, -7.7974e-02,  2.6829e-01,  ..., -4.6016e-02,\n",
      "            1.7219e-01,  2.6615e-02],\n",
      "          [ 7.9594e-02,  3.2436e-03,  6.0609e-02,  ...,  1.4914e-01,\n",
      "           -3.2429e-02,  1.0641e-01],\n",
      "          ...,\n",
      "          [ 1.6519e-01, -1.3203e-01,  1.6247e-01,  ...,  2.9664e-01,\n",
      "            6.3774e-01,  6.2720e-02],\n",
      "          [-8.6046e-03, -3.4263e-02,  1.9302e-03,  ..., -5.9032e-01,\n",
      "           -2.1556e-01, -6.1796e-02],\n",
      "          [ 2.2660e-01,  4.3413e-02,  8.5119e-02,  ..., -3.9580e-03,\n",
      "            7.7475e-01,  4.2665e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4634e-03, -8.5728e-02,  8.0571e-02,  ..., -5.1747e-02,\n",
      "            1.8102e-01, -1.4740e-03],\n",
      "          [ 7.0172e-02,  1.9667e-03,  1.2018e-01,  ...,  9.4110e-02,\n",
      "            1.9057e-01,  4.7180e-02],\n",
      "          [ 1.3766e-01, -1.6116e-03,  3.4750e-02,  ...,  8.7840e-02,\n",
      "            1.5690e-01, -8.5802e-03],\n",
      "          ...,\n",
      "          [ 1.6306e-01,  1.9645e-02,  1.7325e-01,  ...,  4.8664e-01,\n",
      "            8.2055e-01,  5.4387e-01],\n",
      "          [ 2.5902e-01,  4.0953e-02,  1.7754e-01,  ...,  2.0971e-02,\n",
      "            1.1259e-01,  6.7768e-01],\n",
      "          [ 2.0064e-01,  1.4580e-01,  1.8886e-01,  ...,  6.6163e-01,\n",
      "           -4.7657e-01, -8.7092e-02]],\n",
      "\n",
      "         [[ 2.4868e-02,  4.4243e-02,  8.3038e-02,  ...,  1.9975e-02,\n",
      "            3.2544e-02, -2.5171e-02],\n",
      "          [-2.7007e-02, -8.9302e-02,  8.6512e-02,  ..., -8.7285e-02,\n",
      "           -1.8892e-02, -7.3699e-02],\n",
      "          [ 6.4201e-02, -7.3783e-02,  1.6227e-01,  ..., -2.5696e-02,\n",
      "            4.7425e-02, -2.2735e-02],\n",
      "          ...,\n",
      "          [-4.9218e-02,  2.4928e-03, -3.0246e-03,  ..., -1.9897e-01,\n",
      "            8.3603e-01, -3.5847e-01],\n",
      "          [ 9.9963e-02, -1.3365e-01,  9.6872e-02,  ...,  2.6420e-01,\n",
      "           -2.7681e-01, -5.2961e-01],\n",
      "          [-8.2484e-02, -1.2847e-01,  1.1996e-02,  ..., -3.7495e-01,\n",
      "           -3.3162e-02, -5.7228e-01]],\n",
      "\n",
      "         [[ 2.0213e-01,  1.1720e-01,  7.8175e-02,  ...,  1.1535e-01,\n",
      "            9.4007e-02,  3.8156e-03],\n",
      "          [ 1.1807e-01, -5.8936e-02,  1.8341e-01,  ..., -3.8749e-02,\n",
      "            1.2569e-01,  2.1415e-02],\n",
      "          [ 9.2013e-02,  3.8260e-03,  8.5805e-02,  ...,  1.7271e-01,\n",
      "           -2.1579e-02,  1.2790e-01],\n",
      "          ...,\n",
      "          [ 1.8184e-01, -8.2210e-02,  1.7386e-01,  ...,  5.0415e-02,\n",
      "            6.3816e-01, -5.0589e-01],\n",
      "          [ 9.1736e-03, -6.6852e-02,  1.9206e-03,  ...,  1.9272e-01,\n",
      "            1.3707e-01, -3.1349e-01],\n",
      "          [ 1.8209e-01,  2.9982e-02,  6.7629e-02,  ...,  7.2654e-01,\n",
      "           -1.9143e-01, -5.3333e-01]]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward>)], 'last_loss': tensor(31.2518), 'smooth_loss': tensor(31.2518)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pdb) type(self.state_dict)\n",
      "<class 'dict'>\n",
      "(Pdb) self.state_dict.keys()\n",
      "dict_keys(['epoch', 'iteration', 'num_batch', 'skip_validate', 'n_epochs', 'pbar', 'metrics', 'stop_training', 'last_input', 'last_target', 'train', 'stop_epoch', 'skip_step', 'skip_zero', 'skip_bwd', 'last_output', 'last_loss', 'smooth_loss'])\n",
      "(Pdb) last_input.shape\n",
      "*** NameError: name 'last_input' is not defined\n",
      "(Pdb) self.state_dict['last_input'].shape\n",
      "*** AttributeError: 'list' object has no attribute 'shape'\n",
      "(Pdb) type(self.state_dict['last_input'])\n",
      "<class 'list'>\n",
      "(Pdb) self.state_dict['last_input'][0].shape\n",
      "torch.Size([4, 3, 56, 56])\n",
      "(Pdb) type(self.state_dict['last_output'])\n",
      "<class 'list'>\n",
      "(Pdb) self.state_dict['last_output'][0].shape\n",
      "torch.Size([4, 3, 56, 56])\n",
      "(Pdb) self.__class__\n",
      "<class 'fastai.callback.CallbackHandler'>\n",
      "(Pdb) l\n",
      "247  \t    def __call__(self, cb_name, call_mets=True, **kwargs)->None:\n",
      "248  \t        \"Call through to all of the `CallbakHandler` functions.\"\n",
      "249  \t        if call_mets:\n",
      "250  \t            for met in self.metrics: self._call_and_update(met, cb_name, **kwargs)\n",
      "251  \t        for cb in self.callbacks: self._call_and_update(cb, cb_name, **kwargs)\n",
      "252  \t\n",
      "253  \t    def set_dl(self, dl:DataLoader):\n",
      "254  \t        \"Set the current `dl` used.\"\n",
      "255  \t        if hasattr(self, 'cb_dl'): self.callbacks.remove(self.cb_dl)\n",
      "256  \t        if isinstance(dl.dataset, Callback):\n",
      "257  \t            self.callbacks.append(dl.dataset)\n",
      "(Pdb) u\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(251)__call__()\n",
      "-> for cb in self.callbacks: self._call_and_update(cb, cb_name, **kwargs)\n",
      "(Pdb) d\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(241)_call_and_update()\n",
      "-> new = ifnone(getattr(cb, f'on_{cb_name}')(**self.state_dict, **kwargs), dict())\n",
      "(Pdb) l\n",
      "236  \t        self.smoothener = SmoothenValue(self.beta)\n",
      "237  \t        self.state_dict:Dict[str,Union[int,float,Tensor]]=_get_init_state()\n",
      "238  \t\n",
      "239  \t    def _call_and_update(self, cb, cb_name, **kwargs)->None:\n",
      "240  \t        \"Call `cb_name` on `cb` and update the inner state.\"\n",
      "241  ->\t        new = ifnone(getattr(cb, f'on_{cb_name}')(**self.state_dict, **kwargs), dict())\n",
      "242  \t        for k,v in new.items():\n",
      "243  \t            if k not in self.state_dict:\n",
      "244  \t                raise Exception(f\"{k} isn't a valid key in the state of the callbacks.\")\n",
      "245  \t            else: self.state_dict[k] = v\n",
      "246  \t\n",
      "(Pdb) l\n",
      "247  \t    def __call__(self, cb_name, call_mets=True, **kwargs)->None:\n",
      "248  \t        \"Call through to all of the `CallbakHandler` functions.\"\n",
      "249  \t        if call_mets:\n",
      "250  \t            for met in self.metrics: self._call_and_update(met, cb_name, **kwargs)\n",
      "251  \t        for cb in self.callbacks: self._call_and_update(cb, cb_name, **kwargs)\n",
      "252  \t\n",
      "253  \t    def set_dl(self, dl:DataLoader):\n",
      "254  \t        \"Set the current `dl` used.\"\n",
      "255  \t        if hasattr(self, 'cb_dl'): self.callbacks.remove(self.cb_dl)\n",
      "256  \t        if isinstance(dl.dataset, Callback):\n",
      "257  \t            self.callbacks.append(dl.dataset)\n",
      "(Pdb) kwargs\n",
      "{}\n",
      "(Pdb) cb_name\n",
      "'batch_end'\n",
      "(Pdb) self.state_dict.keys()\n",
      "dict_keys(['epoch', 'iteration', 'num_batch', 'skip_validate', 'n_epochs', 'pbar', 'metrics', 'stop_training', 'last_input', 'last_target', 'train', 'stop_epoch', 'skip_step', 'skip_zero', 'skip_bwd', 'last_output', 'last_loss', 'smooth_loss'])\n",
      "(Pdb) d\n",
      "> /userhome/34/h3509807/fastai/CycleGAN-MultiMNIST/src/model_utils/callbacks.py(48)on_batch_end()\n",
      "-> self.G_A.zero_grad(); self.G_B.zero_grad()\n",
      "(Pdb) l\n",
      " 43  \t        self.gen_smter.add_value(self.loss_func.gen_loss.detach().cpu())\n",
      " 44  \t        self.cyc_smter.add_value(self.loss_func.cyc_loss.detach().cpu())\n",
      " 45  \t\n",
      " 46  \t    def on_batch_end(self, last_input, last_output, **kwargs):\n",
      " 47  \t        set_trace()\n",
      " 48  ->\t        self.G_A.zero_grad(); self.G_B.zero_grad()\n",
      " 49  \t        fake_A, fake_B = last_output[0].detach(), last_output[1].detach()\n",
      " 50  \t        real_A, real_B = last_input\n",
      " 51  \t        self._set_trainable(D_A=True)\n",
      " 52  \t        self.D_A.zero_grad()\n",
      " 53  \t        loss_D_A = 0.5 * (self.crit(self.D_A(real_A), True) + self.crit(self.D_A(fake_A), False))\n",
      "(Pdb) u\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(241)_call_and_update()\n",
      "-> new = ifnone(getattr(cb, f'on_{cb_name}')(**self.state_dict, **kwargs), dict())\n",
      "(Pdb) u\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(251)__call__()\n",
      "-> for cb in self.callbacks: self._call_and_update(cb, cb_name, **kwargs)\n",
      "(Pdb) l\n",
      "246  \t\n",
      "247  \t    def __call__(self, cb_name, call_mets=True, **kwargs)->None:\n",
      "248  \t        \"Call through to all of the `CallbakHandler` functions.\"\n",
      "249  \t        if call_mets:\n",
      "250  \t            for met in self.metrics: self._call_and_update(met, cb_name, **kwargs)\n",
      "251  ->\t        for cb in self.callbacks: self._call_and_update(cb, cb_name, **kwargs)\n",
      "252  \t\n",
      "253  \t    def set_dl(self, dl:DataLoader):\n",
      "254  \t        \"Set the current `dl` used.\"\n",
      "255  \t        if hasattr(self, 'cb_dl'): self.callbacks.remove(self.cb_dl)\n",
      "256  \t        if isinstance(dl.dataset, Callback):\n",
      "(Pdb) u\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(308)on_batch_end()\n",
      "-> self('batch_end', call_mets = not self.state_dict['train'])\n",
      "(Pdb) self.state_dict['train']\n",
      "True\n",
      "(Pdb) l\n",
      "303  \t        return self.state_dict['skip_zero']\n",
      "304  \t\n",
      "305  \t    def on_batch_end(self, loss:Tensor)->Any:\n",
      "306  \t        \"Handle end of processing one batch with `loss`.\"\n",
      "307  \t        self.state_dict['last_loss'] = loss\n",
      "308  ->\t        self('batch_end', call_mets = not self.state_dict['train'])\n",
      "309  \t        if self.state_dict['train']:\n",
      "310  \t            self.state_dict['iteration'] += 1\n",
      "311  \t            self.state_dict['num_batch'] += 1\n",
      "312  \t        return self.state_dict['stop_epoch']\n",
      "313  \t\n",
      "(Pdb) d\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(251)__call__()\n",
      "-> for cb in self.callbacks: self._call_and_update(cb, cb_name, **kwargs)\n",
      "(Pdb) d\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(241)_call_and_update()\n",
      "-> new = ifnone(getattr(cb, f'on_{cb_name}')(**self.state_dict, **kwargs), dict())\n",
      "(Pdb) u\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(251)__call__()\n",
      "-> for cb in self.callbacks: self._call_and_update(cb, cb_name, **kwargs)\n",
      "(Pdb) u\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(308)on_batch_end()\n",
      "-> self('batch_end', call_mets = not self.state_dict['train'])\n",
      "(Pdb) d\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(251)__call__()\n",
      "-> for cb in self.callbacks: self._call_and_update(cb, cb_name, **kwargs)\n",
      "(Pdb) cb_name\n",
      "'batch_end'\n",
      "(Pdb) kwargs\n",
      "{}\n",
      "(Pdb) cb\n",
      "CycleGANTrainer\n",
      "learn: Learner(data=ImageDataBunch;\n",
      "\n",
      "Train: LabelList (12000 items)\n",
      "x: ImageTupleList\n",
      "ImageTuple(torch.Size([3, 56, 56]), torch.Size([3, 56, 56])),ImageTuple(torch.Size([3, 56, 56]), torch.Size([3, 56, 56])),ImageTuple(torch.Size([3, 56, 56]), torch.Size([3, 56, 56])),ImageTuple(torch.Size([3, 56, 56]), torch.Size([3, 56, 56])),ImageTuple(torch.Size([3, 56, 56]), torch.Size([3, 56, 56]))\n",
      "y: EmptyLabelList\n",
      ",,,,\n",
      "Path: ../../data/easy;\n",
      "\n",
      "Valid: LabelList (0 items)\n",
      "x: ImageTupleList\n",
      "\n",
      "y: EmptyLabelList\n",
      "\n",
      "Path: ../../data/easy;\n",
      "\n",
      "Test: None, model=CycleGAN(\n",
      "  (D_A): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (D_B): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (G_A): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (11): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (12): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (13): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (14): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (15): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (16): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (19): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (22): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (23): Tanh()\n",
      "  )\n",
      "  (G_B): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (11): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (12): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (13): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (14): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (15): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (16): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (19): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (22): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (23): Tanh()\n",
      "  )\n",
      "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.5, 0.99)), loss_func=CycleGanLoss(\n",
      "  (cgan): CycleGAN(\n",
      "    (D_A): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "      (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (D_B): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "      (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (G_A): Sequential(\n",
      "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (9): ReLU(inplace=True)\n",
      "      (10): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (11): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (12): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (13): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (14): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (15): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (16): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (17): ReLU(inplace=True)\n",
      "      (18): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (19): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (20): ReLU(inplace=True)\n",
      "      (21): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (22): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (23): Tanh()\n",
      "    )\n",
      "    (G_B): Sequential(\n",
      "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (9): ReLU(inplace=True)\n",
      "      (10): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (11): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (12): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (13): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (14): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (15): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (16): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (17): ReLU(inplace=True)\n",
      "      (18): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (19): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (20): ReLU(inplace=True)\n",
      "      (21): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (22): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (23): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (crit): AdaptiveLoss()\n",
      "), metrics=[], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('../../data/easy'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'src.model_utils.callbacks.CycleGANTrainer'>], callbacks=[], layer_groups=[Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "  (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "  (12): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (13): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (14): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (15): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (16): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (17): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (18): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (19): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (20): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "  (21): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (22): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (23): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "  (24): ReflectionPad2d((3, 3, 3, 3))\n",
      "  (25): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "  (26): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (27): ReLU(inplace=True)\n",
      "  (28): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (29): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (30): ReLU(inplace=True)\n",
      "  (31): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (32): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (33): ReLU(inplace=True)\n",
      "  (34): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (35): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (36): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (37): ReLU(inplace=True)\n",
      "  (38): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (39): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (40): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (41): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (42): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (43): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (44): ReLU(inplace=True)\n",
      "  (45): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (46): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (47): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (48): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (49): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (50): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (51): ReLU(inplace=True)\n",
      "  (52): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (53): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (54): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (55): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (56): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (57): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (58): ReLU(inplace=True)\n",
      "  (59): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (60): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (61): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (62): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (63): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (64): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (65): ReLU(inplace=True)\n",
      "  (66): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (67): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (68): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (69): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (70): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (71): ReLU(inplace=True)\n",
      "  (72): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (73): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (74): ReLU(inplace=True)\n",
      "  (75): ReflectionPad2d((3, 3, 3, 3))\n",
      "  (76): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "  (77): Tanh()\n",
      "  (78): ReflectionPad2d((3, 3, 3, 3))\n",
      "  (79): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "  (80): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (81): ReLU(inplace=True)\n",
      "  (82): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (83): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (84): ReLU(inplace=True)\n",
      "  (85): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (86): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (87): ReLU(inplace=True)\n",
      "  (88): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (89): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (90): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (91): ReLU(inplace=True)\n",
      "  (92): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (93): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (94): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (95): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (96): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (97): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (98): ReLU(inplace=True)\n",
      "  (99): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (100): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (101): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (102): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (103): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (104): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (105): ReLU(inplace=True)\n",
      "  (106): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (107): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (108): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (109): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (110): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (111): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (112): ReLU(inplace=True)\n",
      "  (113): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (114): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (115): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (116): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (117): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (118): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (119): ReLU(inplace=True)\n",
      "  (120): ReflectionPad2d((1, 1, 1, 1))\n",
      "  (121): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (122): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (123): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (124): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (125): ReLU(inplace=True)\n",
      "  (126): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (127): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (128): ReLU(inplace=True)\n",
      "  (129): ReflectionPad2d((3, 3, 3, 3))\n",
      "  (130): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "  (131): Tanh()\n",
      ")], add_time=True, silent=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pdb) cb_name\n",
      "'batch_end'\n",
      "(Pdb) l\n",
      "246  \t\n",
      "247  \t    def __call__(self, cb_name, call_mets=True, **kwargs)->None:\n",
      "248  \t        \"Call through to all of the `CallbakHandler` functions.\"\n",
      "249  \t        if call_mets:\n",
      "250  \t            for met in self.metrics: self._call_and_update(met, cb_name, **kwargs)\n",
      "251  ->\t        for cb in self.callbacks: self._call_and_update(cb, cb_name, **kwargs)\n",
      "252  \t\n",
      "253  \t    def set_dl(self, dl:DataLoader):\n",
      "254  \t        \"Set the current `dl` used.\"\n",
      "255  \t        if hasattr(self, 'cb_dl'): self.callbacks.remove(self.cb_dl)\n",
      "256  \t        if isinstance(dl.dataset, Callback):\n",
      "(Pdb) y\n",
      "*** NameError: name 'y' is not defined\n",
      "(Pdb) u\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(308)on_batch_end()\n",
      "-> self('batch_end', call_mets = not self.state_dict['train'])\n",
      "(Pdb) d\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(251)__call__()\n",
      "-> for cb in self.callbacks: self._call_and_update(cb, cb_name, **kwargs)\n",
      "(Pdb) d\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(241)_call_and_update()\n",
      "-> new = ifnone(getattr(cb, f'on_{cb_name}')(**self.state_dict, **kwargs), dict())\n",
      "(Pdb) d\n",
      "> /userhome/34/h3509807/fastai/CycleGAN-MultiMNIST/src/model_utils/callbacks.py(48)on_batch_end()\n",
      "-> self.G_A.zero_grad(); self.G_B.zero_grad()\n",
      "(Pdb) l\n",
      " 43  \t        self.gen_smter.add_value(self.loss_func.gen_loss.detach().cpu())\n",
      " 44  \t        self.cyc_smter.add_value(self.loss_func.cyc_loss.detach().cpu())\n",
      " 45  \t\n",
      " 46  \t    def on_batch_end(self, last_input, last_output, **kwargs):\n",
      " 47  \t        set_trace()\n",
      " 48  ->\t        self.G_A.zero_grad(); self.G_B.zero_grad()\n",
      " 49  \t        fake_A, fake_B = last_output[0].detach(), last_output[1].detach()\n",
      " 50  \t        real_A, real_B = last_input\n",
      " 51  \t        self._set_trainable(D_A=True)\n",
      " 52  \t        self.D_A.zero_grad()\n",
      " 53  \t        loss_D_A = 0.5 * (self.crit(self.D_A(real_A), True) + self.crit(self.D_A(fake_A), False))\n",
      "(Pdb) u\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(241)_call_and_update()\n",
      "-> new = ifnone(getattr(cb, f'on_{cb_name}')(**self.state_dict, **kwargs), dict())\n",
      "(Pdb) u\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(251)__call__()\n",
      "-> for cb in self.callbacks: self._call_and_update(cb, cb_name, **kwargs)\n",
      "(Pdb) u\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(308)on_batch_end()\n",
      "-> self('batch_end', call_mets = not self.state_dict['train'])\n",
      "(Pdb) u\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/basic_train.py(104)fit()\n",
      "-> if cb_handler.on_batch_end(loss): break\n",
      "(Pdb) d\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(308)on_batch_end()\n",
      "-> self('batch_end', call_mets = not self.state_dict['train'])\n",
      "(Pdb) l\n",
      "303  \t        return self.state_dict['skip_zero']\n",
      "304  \t\n",
      "305  \t    def on_batch_end(self, loss:Tensor)->Any:\n",
      "306  \t        \"Handle end of processing one batch with `loss`.\"\n",
      "307  \t        self.state_dict['last_loss'] = loss\n",
      "308  ->\t        self('batch_end', call_mets = not self.state_dict['train'])\n",
      "309  \t        if self.state_dict['train']:\n",
      "310  \t            self.state_dict['iteration'] += 1\n",
      "311  \t            self.state_dict['num_batch'] += 1\n",
      "312  \t        return self.state_dict['stop_epoch']\n",
      "313  \t\n",
      "(Pdb) d\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(251)__call__()\n",
      "-> for cb in self.callbacks: self._call_and_update(cb, cb_name, **kwargs)\n",
      "(Pdb) \n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(241)_call_and_update()\n",
      "-> new = ifnone(getattr(cb, f'on_{cb_name}')(**self.state_dict, **kwargs), dict())\n",
      "(Pdb) u\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(251)__call__()\n",
      "-> for cb in self.callbacks: self._call_and_update(cb, cb_name, **kwargs)\n",
      "(Pdb) d\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(241)_call_and_update()\n",
      "-> new = ifnone(getattr(cb, f'on_{cb_name}')(**self.state_dict, **kwargs), dict())\n",
      "(Pdb) d\n",
      "> /userhome/34/h3509807/fastai/CycleGAN-MultiMNIST/src/model_utils/callbacks.py(48)on_batch_end()\n",
      "-> self.G_A.zero_grad(); self.G_B.zero_grad()\n",
      "(Pdb) u\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(241)_call_and_update()\n",
      "-> new = ifnone(getattr(cb, f'on_{cb_name}')(**self.state_dict, **kwargs), dict())\n",
      "(Pdb) u\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(251)__call__()\n",
      "-> for cb in self.callbacks: self._call_and_update(cb, cb_name, **kwargs)\n",
      "(Pdb) u\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(308)on_batch_end()\n",
      "-> self('batch_end', call_mets = not self.state_dict['train'])\n",
      "(Pdb) u\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/basic_train.py(104)fit()\n",
      "-> if cb_handler.on_batch_end(loss): break\n",
      "(Pdb) d\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(308)on_batch_end()\n",
      "-> self('batch_end', call_mets = not self.state_dict['train'])\n",
      "(Pdb) d\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(251)__call__()\n",
      "-> for cb in self.callbacks: self._call_and_update(cb, cb_name, **kwargs)\n",
      "(Pdb) u\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(308)on_batch_end()\n",
      "-> self('batch_end', call_mets = not self.state_dict['train'])\n",
      "(Pdb) d\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(251)__call__()\n",
      "-> for cb in self.callbacks: self._call_and_update(cb, cb_name, **kwargs)\n",
      "(Pdb) d\n",
      "> /userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py(241)_call_and_update()\n",
      "-> new = ifnone(getattr(cb, f'on_{cb_name}')(**self.state_dict, **kwargs), dict())\n",
      "(Pdb) self.state_dict.keys()\n",
      "dict_keys(['epoch', 'iteration', 'num_batch', 'skip_validate', 'n_epochs', 'pbar', 'metrics', 'stop_training', 'last_input', 'last_target', 'train', 'stop_epoch', 'skip_step', 'skip_zero', 'skip_bwd', 'last_output', 'last_loss', 'smooth_loss'])\n",
      "(Pdb) exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8587f3539821>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_validate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;34m\"Handle end of processing one batch with `loss`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch_end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_mets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iteration'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, cb_name, call_mets, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcall_mets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_and_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_and_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_dl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36m_call_and_update\u001b[0;34m(self, cb, cb_name, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_and_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;34m\"Call `cb_name` on `cb` and update the inner state.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'on_{cb_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/CycleGAN-MultiMNIST/src/ipynb/../../src/model_utils/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, last_input, last_output, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_B\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mfake_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mreal_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/CycleGAN-MultiMNIST/src/ipynb/../../src/model_utils/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, last_input, last_output, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_B\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mfake_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mreal_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userhome/31/h3509807/anaconda3/envs/fastai-2020/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
